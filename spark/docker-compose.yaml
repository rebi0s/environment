version: "3.7"
services:
    spark-master:
        container_name: spark_master
        build:
            context: ./docker/.
            dockerfile: spark.dockerfile
        ports:
            - 9090:8080
            - 7077:7077
            - 10000:10000
            - 10025:10025
            - 10026:10026
            - 10027:10027
        restart: always
        volumes:
            - ../../spark/master/apps:/opt/spark-apps
            - ../../spark/master/data:/opt/spark-data
            - ../../spark/master/logs:/opt/spark/logs
            - ../../spark/master/spark-events:/workspace/spark-events
            - ../../spark/etl-rebios:/home/etl-rebios
        environment:
            - SPARK_LOCAL_IP=spark_master
            - SPARK_WORKLOAD=master
        extra_hosts:
            - host.docker.internal:host-gateway
        env_file:
          - docker/.env
        deploy:
            resources:
               limits:
                  cpus: '6'
                  memory: 16G
               reservations:
                  cpus: '2'
                  memory: 4G  

    spark-worker-a:
        container_name: spark_worker_a
        build:
            context: ./docker/.
            dockerfile: spark.dockerfile
        ports:
            - 9091:8080
            - 7000:7000
        depends_on:
            - spark-master
        environment:
            - SPARK_MASTER=spark://host.docker.internal:7077
            - SPARK_WORKER_CORES=2
            - SPARK_WORKER_MEMORY=4G
            - SPARK_DRIVER_MEMORY=4G
            - SPARK_EXECUTOR_MEMORY=4G
            - SPARK_WORKLOAD=worker
            - SPARK_LOCAL_IP=spark-worker-a
        restart: always
        deploy:
            resources:
               limits:
                  cpus: '2'
                  memory: 4G
               reservations:
                  cpus: '1'
                  memory: 2G
        extra_hosts:
            - host.docker.internal:host-gateway
        volumes:
            - ../../spark/spark-worker-a/apps:/opt/spark-apps
            - ../../spark/spark-worker-a/data:/opt/spark-data
            - ../../spark/spark-worker-a/logs:/opt/spark/logs
            - ../../spark/spark-worker-a/spark-events:/workspace/spark-events
        env_file:
          - docker/.env
    spark-worker-b:
        container_name: spark_worker_b
        build:
            context: ./docker/.
            dockerfile: spark.dockerfile
        ports:
            - 9092:8080
            - 7001:7000
        depends_on:
            - spark-master
        environment:
            - SPARK_MASTER=spark://host.docker.internal:7077
            - SPARK_WORKER_CORES=2
            - SPARK_WORKER_MEMORY=4G
            - SPARK_DRIVER_MEMORY=4G
            - SPARK_EXECUTOR_MEMORY=4G
            - SPARK_WORKLOAD=worker
            - SPARK_LOCAL_IP=spark-worker-b
        restart: always
        extra_hosts:
            - host.docker.internal:host-gateway
        deploy:
            resources:
               limits:
                  cpus: '2'
                  memory: 4G
               reservations:
                  cpus: '1'
                  memory: 2G
        volumes:
            - ../../spark/spark-worker-b/apps:/opt/spark-apps
            - ../../spark/spark-worker-b/data:/opt/spark-data
            - ../../spark/spark-worker-b/logs:/opt/spark/logs
            - ../../spark/spark-worker-b/spark-events:/workspace/spark-events
        env_file:
          - docker/.env
