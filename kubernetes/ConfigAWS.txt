################################################################
#Export Database Dumps
#


pg_dump -U postgres -W -F c -d db_iceberg > db_iceberg.dump

pg_dump -U postgres -W -F c -d db_hue > db_hue.dump

pg_dump -U postgres -W -F c -d db_superset > db_superset.dump

################################################
#Copy Dump File
sudo docker cp iceberg_postgres_db:/home/db_iceberg.dump . 

sudo docker cp iceberg_postgres_db:/home/db_hue.dump . 

sudo docker cp iceberg_postgres_db:/home/db_superset.dump . 


#Copy Dump to S3
aws s3 cp db_iceberg.dump  s3://rebios-test-env/rebios-backup/

aws s3 cp db_hue.dump  s3://rebios-test-env/rebios-backup/

aws s3 cp db_superset.dump  s3://rebios-test-env/rebios-backup/

#Copy Dump From S3

aws s3 cp  s3://rebios-test-env/rebios-backup/db_hue.dump .

aws s3 cp  s3://rebios-test-env/rebios-backup/db_iceberg.dump .

aws s3 cp  s3://rebios-test-env/rebios-backup/db_superset.dump .


# Deploy Postgres on Kubernetes

kc delete namespace rebios-postgres 

kc create namespace rebios-postgres 

kc apply -n rebios-postgres -f postgres-configmap.yaml

kc get configmap

kc apply -n rebios-postgres -f psql-pv.yaml

kc get pv

kc apply -n rebios-postgres -f psql-claim.yaml

kc -n rebios-postgres get pvc

kc apply -n rebios-postgres -f ps-deployment.yaml

kc -n rebios-postgres get deployments

#Check Postgres pods

kc get pods -n rebios-postgres

kc get services -n rebios-postgres

kc apply -n rebios-postgres -f ps-service.yaml

kc get svc -n rebios-postgres
#Connect to POD
kc exec -n rebios-postgres -it postgres-59d7fddd4-4tdf7 -- /bin/bash

#Connect to Postgres
psql --user=postgres --port=5432
psql -h localhost -U postgres --password -p 5432 

#Create Database and Users
CREATE DATABASE db_iceberg;
CREATE DATABASE db_hue;
CREATE DATABASE db_superset;
CREATE DATABASE db_datahub;
UPDATE pg_database SET datallowconn = 'true' WHERE datname = 'db_iceberg';
UPDATE pg_database SET datallowconn = 'true' WHERE datname = 'db_hue';
UPDATE pg_database SET datallowconn = 'true' WHERE datname = 'db_superset';
UPDATE pg_database SET datallowconn = 'true' WHERE datname = 'db_datahub';

CREATE ROLE role_iceberg LOGIN PASSWORD 'hNXz35UBRcAC';
CREATE ROLE role_hue LOGIN PASSWORD 'zahjo1poJeer';
CREATE ROLE role_superset LOGIN PASSWORD '7OL1LPsJ7SGI';
CREATE ROLE role_datahub LOGIN PASSWORD '5hFi2ngSI8Xe';

GRANT CONNECT ON DATABASE db_iceberg TO role_iceberg;
GRANT CONNECT ON DATABASE db_hue TO role_hue;
GRANT CONNECT ON DATABASE db_datahub TO role_datahub;
GRANT CONNECT ON DATABASE db_superset TO role_superset;


GRANT ALL privileges ON SCHEMA public TO role_hue;
GRANT USAGE, SELECT ON ALL SEQUENCES IN SCHEMA public TO role_hue;

GRANT ALL privileges ON SCHEMA public TO role_iceberg;
GRANT USAGE, SELECT ON ALL SEQUENCES IN SCHEMA public TO role_iceberg;

GRANT ALL privileges ON SCHEMA public TO role_superset;
GRANT USAGE, SELECT ON ALL SEQUENCES IN SCHEMA public TO role_superset;

GRANT ALL privileges ON SCHEMA public TO role_datahub;
GRANT USAGE, SELECT ON ALL SEQUENCES IN SCHEMA public TO role_datahub;

#Restore Databases
pg_restore  --dbname=db_iceberg --user=postgres --port=5432 --clean -d db_iceberg /tmp/db_iceberg.dump
pg_restore  --dbname=db_hue --user=postgres --port=5432 --clean -d db_hue /tmp/db_hue.dump
pg_restore  --dbname=db_superset --user=postgres --port=5432 --clean -d db_superset /tmp/db_superset.dump

#Install Spark
kc delete namespace rebios-spark

kc create namespace rebios-spark

helm install -n rebios-spark spark oci://registry-1.docker.io/bitnamicharts/spark -f values.yaml

kc -n rebios-spark get services

kc -n rebios-spark get pods 

kc -n rebios-spark logs spark-master-0
#Master
kc exec -it -n rebios-spark spark-master-0   -- /bin/bash
kc exec -it -n rebios-spark spark-worker-0   -- /bin/bash
kc exec -it -n rebios-spark spark-worker-1   -- /bin/bash


kc exec -it -n spark-master-677447f567-42vjc   -- /bin/bash



34.228.176.207:30008


kc port-forward -n rebios-spark service/spark-master 7890:7890 --address 0.0.0.0

#Create SSH Tunnel
ssh -i "reBI0S_key_us_east_1.pem" -L 7890:10.152.183.76:7890 ubuntu@34.228.176.207



8080

./start-worker.sh spark://34.228.176.207:7077

./start-workers.sh spark://34.228.176.207:7077

spark-master-svc   NodePort    10.152.183.20   <none>        7077:30571/TCP,80:30792/TCP,10000:32177/TCP   7m12s

kc -n rebios-spark logs spark-master-677447f567-42vjc
kc -n rebios-spark logs spark-worker-685cf55bc4-46pwq
kc -n rebios-spark logs spark-worker-685cf55bc4-g76zj



Thrift
34.228.176.207:31629

54.88.111.158:8888

31588
http://34.228.176.207:31588

http://34.228.176.207:30760

sh sbin/stop-thriftserver.sh
sh /scripts/start-spark-thrift.sh

sh /scripts/start-spark-sql.sh

echo "$(ps aux)"

NOTES:
CHART NAME: spark
CHART VERSION: 9.3.1
APP VERSION: 3.5.3

Did you know there are enterprise versions of the Bitnami catalog? For enhanced secure software supply chain features, unlimited pulls from Docker, LTS support, or application customization, see Bitnami Premium or Tanzu Application Catalog. See https://www.arrow.com/globalecs/na/vendors/bitnami for more information.

** Please be patient while the chart is being deployed **

1. Get the Spark master WebUI URL by running these commands:

  export HOSTNAME=$(kubectl get ingress --namespace rebios-spark spark-ingress -o jsonpath='{.spec.rules[0].host}')
  echo "Spark-master URL: http://$HOSTNAME/"

2. Submit an application to the cluster:

  To submit an application to the cluster the spark-submit script must be used. That script can be
  obtained at https://github.com/apache/spark/tree/master/bin. Also you can use kubectl run.

  Run the commands below to obtain the master IP and submit your application.

  export EXAMPLE_JAR=$(kubectl exec -ti --namespace rebios-spark spark-worker-0 -- find examples/jars/ -name 'spark-example*\.jar' | tr -d '\r')
  export SUBMIT_PORT=$(kubectl get --namespace rebios-spark -o jsonpath="{.spec.ports[?(@.name=='cluster')].nodePort}" services spark-master-svc)
  export SUBMIT_IP=$(kubectl get nodes --namespace rebios-spark -o jsonpath="{.items[0].status.addresses[0].address}")

  kubectl run --namespace rebios-spark spark-client --rm --tty -i --restart='Never' \
    --image docker.io/bitnami/spark:3.5.3-debian-12-r3 \
    -- spark-submit --master spark://$SUBMIT_IP:$SUBMIT_PORT \
    --class org.apache.spark.examples.SparkPi \
    --deploy-mode cluster \
    $EXAMPLE_JAR 1000

** IMPORTANT: When submit an application the --master parameter should be set to the service IP, if not, the application will not resolve the master. **

http://34.228.176.207:31717

#Configure Superset


aws s3 cp superset.db  s3://rebios-test-env/rebios-backup/

aws s3 cp s3://rebios-test-env/rebios-backup/superset.db  .

kc delete namespace rebios-superset

kc create namespace rebios-superset

kc -n rebios-superset delete pv superset-volume  

kc -n rebios-superset delete pv redis-volume  

kc -n rebios-superset delete pvc superset-data

kc apply -n rebios-superset -f pv.yaml

kc apply -n rebios-superset -f pv_redis.yaml

kc -n rebios-superset get pv 

kc apply -n rebios-superset -f pvc.yaml


kc -n rebios-superset get pvc

kc apply -n rebios-superset -f pvc_redis.yaml


kc apply -n rebios-superset -f configmap.yaml

kc apply -n rebios-superset -f scripts.yaml

sudo docker login --username jrosses --password DtrifNopan@111727

sudo docker pull jrosses/rebios-superset:1.0.2

kc apply -n rebios-superset -f bash.yaml

kc -n rebios-superset get pods

kc -n rebios-superset describe pods superset-bash-869dd8fd8d-hrvnc

kc exec -it -n rebios-superset superset-bash-869dd8fd8d-hrvnc   -- /bin/bash

kc -n rebios-superset delete statefulsets superset-redis

kc apply -n rebios-superset -f redis.yaml

kc -n rebios-superset get pods

kc apply -n rebios-superset -f service-redis.yaml

kc apply -n rebios-superset -f superset-beat.yaml

kc -n rebios-superset get pods

kc apply -n rebios-superset -f superset-worker.yaml

kc -n rebios-superset get pods

kc apply -n rebios-superset -f superset.yaml

kc -n rebios-superset get pods

kc apply -n rebios-superset -f service-superset.yaml

kc apply -n rebios-superset -f ingress.yaml
###################################################
http://34.228.176.207:32378
###################################################
#Configure hue
kc delete namespace rebios-hue

kc create namespace rebios-hue

kc apply -n rebios-hue -f cm.yaml

kc apply -n rebios-hue -f hue.yaml

kc apply -n rebios-hue -f service.yaml

kc -n rebios-hue get pods

kc -n rebios-hue get services

http://54.88.111.158:32088

http://34.228.176.207:32088
rebiosadmin - 9t3GuWCf4M3D
###################################################
#Configure DataHub

kc delete namespace rebios-datahub

kc create namespace rebios-datahub

kc -n rebios-datahub create secret generic mysql-secrets --from-literal=mysql-root-password=rebios-datahub

kc -n rebios-datahub describe secret mysql-secrets
 
kc -n rebios-datahub create secret generic neo4j-secrets --from-literal=neo4j-password=rebios-datahub

kc -n rebios-datahub describe secret neo4j-secrets

kc -n rebios-datahub create secret generic postgresql-secrets --from-literal=postgres-password=postgres,replication-password=postgres,password=postgres

kc -n rebios-datahub describe secret postgresql-secrets


helm repo add datahub https://helm.datahubproject.io/

helm -n rebios-datahub install prerequisites datahub/datahub-prerequisites -f values-prerequisites.yaml



export user=ue10797
kc config set-credentials uks-$user --embed-certs --client-certificate ./$user.csr --client-key ./$user.key
kc config set-cluster uks --embed-certs --certificate-authority kube-ca.crt --server https://177.220.120.104:6443
kc config set-context uks --cluster uks --user uks-$user --namespace rebios
kc config use-context uks

kc -n rebios-superset patch svc superset --type='json' -p  '[{"op":"replace","path":"/spec/type","value":"NodePort"},{"op":"replace","path":"/spec/ports/0/nodePort","value":30040}]'
